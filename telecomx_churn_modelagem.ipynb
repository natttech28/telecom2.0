{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Telecom X - Parte 2: Modelagem Preditiva do Churn\n",
    "\n",
    "Neste notebook, damos continuidade ao projeto iniciado na Parte 1 (ETL e An√°lise Explorat√≥ria).\n",
    "\n",
    "O objetivo aqui √© **construir modelos preditivos capazes de prever o churn de clientes**, identificando os principais fatores que influenciam a evas√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar dados tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados tratados da Parte 1\n",
    "df = pd.read_csv('dados_tratados.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Separar vari√°veis preditoras (X) e alvo (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Churn'])\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pr√©-processamento (Encoding + Normaliza√ß√£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar colunas num√©ricas e categ√≥ricas\n",
    "num_cols = X.select_dtypes(include=['int64','float64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns\n",
    "\n",
    "# Pr√©-processador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ])\n",
    "\n",
    "# Separar treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinar modelos preditivos (Regress√£o Log√≠stica e Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress√£o Log√≠stica\n",
    "log_reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', LogisticRegression(max_iter=1000))])\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                     ('model', RandomForestClassifier(n_estimators=200, random_state=42))])\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Avalia√ß√£o dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar Regress√£o Log√≠stica\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "print('=== Regress√£o Log√≠stica ===')\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "print('AUC:', roc_auc_score(y_test, log_reg.predict_proba(X_test)[:,1]))\n",
    "\n",
    "# Avaliar Random Forest\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print('\n=== Random Forest ===')\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print('AUC:', roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Import√¢ncia das vari√°veis (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = (num_cols.tolist() + list(rf.named_steps['preprocessor']\n",
    "                                          .transformers_[1][1]\n",
    "                                          .get_feature_names_out(cat_cols)))\n",
    "importances = rf.named_steps['model'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Import√¢ncia das vari√°veis (Random Forest)')\n",
    "plt.barh(range(10), importances[indices][:10], align='center')\n",
    "plt.yticks(range(10), [feature_names[i] for i in indices[:10]])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclus√µes Estrat√©gicas\n",
    "\n",
    "- Clientes com **contratos mensais** e **menor tempo de perman√™ncia (tenure baixo)** s√£o mais propensos a cancelar.\n",
    "- Pre√ßos altos de mensalidade tamb√©m aparecem como fator importante.\n",
    "- Sugest√£o: focar em programas de fideliza√ß√£o, descontos para novos clientes e pacotes de longo prazo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}